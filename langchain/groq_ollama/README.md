Bias + weights -> parameters

Download Ollama and install it, thats it. 

https://github.com/ollama/ollama

-- open the command Prompt -> ollama run llama3.2:1b [check in the gitHub above link]

-- Context Size varies from model to model. Some support 8K some 16K. Context comes
-- from Vector store. Context size is more, better performance from LLM. Will too much 
-- conext size make the LLM confused ? 